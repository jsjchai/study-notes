# 数据分区
## 定义
> 每一条数据（或者每条记录，每行或每个文档）只属于冒个特定分区
## 目的
> 提高可扩展性
## 主要目标
> 将数据和查询负载均匀分布在所有节点上
## 分区方法
1. **基于关键字区间分区**
> 每个分区分配一段连续的关键字或者关键字区间范围（以最小值和最大值指示）
* 缺点：某些访问访问模式会导致热点
2. **基于关键字哈希值分区**
> 一个处理字符串的32位哈希函数，当输入某个字符串，它会返回一个0和2³²~1之间近似随机分布的数值
* 可以处理数据倾斜并使其均匀分布
* 可以减轻热点，但无法做到完全避免
## 分区与二级索引
> 二级索引用来加速特定值的查询，但不能规整的地映射到分区
1. 基于文档分区的二级索引（本地索引）
* 每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中的数据
* 分散/聚集，查询代价高
* MongoDB,Elasticsearch等支持基于文档分区二级索引
2. 基于词条的二级索引分区
* 对所有的数据构建全局索引
* 词条分区
* 读取高效
* 写入速度慢且非常复杂
## 分区再平衡
> 节点迁移，使负载、数据存储、读写均匀分布
* 固定数量的分区（远超实际节点数的分区数）
* 动态分区
## 查询路由到正确的分区
* 分区感知负载均衡（zookeeper等）
* 并行查询执行
