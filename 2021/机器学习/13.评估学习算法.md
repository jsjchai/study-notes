## 评估学习算法
> 在机器学习中，偏差（bias）反映了模型无法描述数据规律，而方差（variance）反映了模型对训练集过度敏感，而丢失了数据规律，高偏差和高方差都会造成新数据到来时，模型给出错误的预测
### 评估假设

### 诊断偏差与方差
#### 检查多项式 d 的次数与我们假设的欠拟合或过拟合之间的关系
* 需要区分偏差或方差是否是导致错误预测的问题
* 高偏差是欠拟合，高方差是过拟合。理想情况下，我们需要在这两者之间找到一个中庸之道

### 决策过程
#### 修复高方差
* 获得更多训练示例 
* 尝试较小的功能集
* 增加 λ
#### 修复高偏差
* 添加功能 
* 添加多项式特征  
* 减小 λ

### 诊断神经网络
> 使用单个隐藏层是一个很好的初始默认设置。您可以使用交叉验证集在多个隐藏层上训练您的神经网络。然后，您可以选择性能最佳的一个
* 参数较少的神经网络容易欠拟合,计算成本低
* 具有更多参数的大型神经网络容易过拟合,计算成本高.在这种情况下，您可以使用正则化（增加 λ）来解决过拟合问题。

### 模型复杂度影响
* 低阶多项式（模型复杂度低）具有高偏差和低方差。在这种情况下，模型的一致性很差
* 高阶多项式（模型复杂度高）非常适合训练数据，而测试数据非常差。这些对训练数据的偏差很小，但方差很大
* 实际上，我们希望选择一个介于两者之间的模型，它可以很好地概括，但也能很好地拟合数据

### 解决机器学习问题的推荐方法是
* 从一个简单的算法开始，快速实现它，并在交叉验证数据上尽早对其进行测试
* 绘制学习曲线以确定更多数据、更多特征等是否有帮助
* 手动检查交叉验证集中示例的错误，并尝试找出大多数错误发生的趋势

### 性能度量
> 为了了解模型的泛化能力，我们需要用某个指标来衡量.有了一个指标，我们就可以对比不同模型了，从而知道哪个模型相对好，那个模型相对差，并通过这个指标来进一步调参逐步优化我们的模型

#### 精准率 Precision
> 精准率（Precision）又叫查准率，它是针对预测结果 而言的，它的含义是在所有被预测为正的样本中实际为正的样本的概率

#### 召回率 Recall
> 召回率（Recall）又叫查全率，它是针对原样本而言的，它的含义是在实际为正的样本中被预测为正样本的概率

### 参考文档
* [一文让你彻底理解准确率，精准率，召回率，真正率，假正率，ROC/AUC](https://www.6aiq.com/article/1549986548173)
* [机器学习算法评估](https://halfrost.com/advice_for_applying_machine_learning/)

