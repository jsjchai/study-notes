## 支持向量机
> **支持向量机**（Support Vector Machine, SVM）是一类按监督学习（supervised learning）方式对数据进行二元分类的广义线性分类器（generalized linear classifier），其决策边界是对学习样本求解的最大边距超平面（maximum-margin hyperplane）。SVM使用铰链损失函数（hinge loss）计算经验风险（empirical risk）并在求解系统中加入了正则化项以优化结构风险（structural risk），是一个具有稀疏性和稳健性的分类器。SVM可以通过核方法（kernel method）进行非线性分类，是常见的**核学习**（kernel learning）方法之一
* 支持向量机在高维或无限维空间中构造超平面或超平面集合，其可以用于分类、回归或其他任务。直观来说，分类边界距离最近的训练资料点越远越好，因为这样可以缩小分类器的泛化误

### 线性分类器
> 对于支持向量机来说，数据点被视为 {\displaystyle p}p 维向量，而我们想知道是否可以用 {\displaystyle (p-1)}{\displaystyle (p-1)} 维超平面来分开这些点

### 线性SVM
#### 硬间隔
> 如果这些训练数据是线性可分的，可以选择分离两类数据的两个平行超平面，使得它们之间的距离尽可能大。在这两个超平面范围内的区域称为“间隔”，最大间隔超平面是位于它们正中间的超平面
#### 软间隔
![image](https://user-images.githubusercontent.com/13389058/154791443-f5e2677f-1796-4029-9d1a-a8931f242a94.png)

### 非线性分类
> 最大间隔超平面算法构造了一个线性分类器
#### 计算SVM分类器
#### 对偶型
#### 核方法
