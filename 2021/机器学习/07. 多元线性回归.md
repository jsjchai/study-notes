## 定义
> 在回归分析中，如果有两个或两个以上的自变量，就称为多元回归。事实上，一种现象常常是与多个因素相联系的，由多个自变量的最优组合共同来预测或估计因变量，比只用一个自变量进行预测或估计更有效，更符合实际。因此多元线性回归比一元线性回归的实用意义更大
## 假设函数的多变量形式
* h<sub>θ</sub>(x)=θ<sub>0</sub>+θ<sub>1</sub>x<sub>1</sub>+θ<sub>2</sub>x<sub>2</sub>+...+θ<sub>n</sub>x<sub>n</sub>
* 假设x<sub>0</sub><sup>(i)</sup>(i∈1,…,m)
![image](https://user-images.githubusercontent.com/13389058/144733238-995d7ab2-3c56-470f-a807-69eeb78cf4f8.png)
## 多个变量的梯度下降
![image](https://user-images.githubusercontent.com/13389058/144766722-02930954-c7e7-4830-a88b-67a8b3f0779e.png)
![image](https://user-images.githubusercontent.com/13389058/144766728-fa0800fc-be7b-4b64-ae70-c7b9d0e0e4d2.png)

## 数据归一化
> **数据映射到同一尺度**
* 特征缩放

![image](https://user-images.githubusercontent.com/13389058/144867039-5166a7f1-2fc4-4fad-a08b-e7f39518485b.png)
* **均值归一化**

![image](https://user-images.githubusercontent.com/13389058/144866936-798d43dd-d99c-4ae1-a82f-bcefe850171f.png)

