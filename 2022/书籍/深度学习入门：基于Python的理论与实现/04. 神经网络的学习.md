## 神经网络的学习
### 学习
> 这里所说的“学习”是指从训练数据中自动获取最优权重参数的过程

### 神经网络的特征
> 神经网络的特征就是可以从数据中学习。所谓“从数据中学习”，是指可以由数据自动决定权重参数的值

### 感知机收敛定理
> 通过有限次数的学习，线性可分问题是可解的。但是，非线性可分问题则无法通过（自动）学习来解决。

### 特征量
> 指可以从输入数据（输入图像）中准确地提取本质数据（重要的数据）的转换器

![image](https://user-images.githubusercontent.com/13389058/157394417-c9b6301f-5231-45c8-9217-5a3f32e4d70a.png)

### 训练数据
> 使用训练数据进行学习，寻找最优的参数

### 测试数据
> 使用测试数据评价训练得到的模型的实际能力

### 泛化能力
> 泛化能力是指处理未被观察过的数据（不包含在训练数据中的数据）的能力

### 过拟合
> 只对某个数据集过度拟合的状态

### 损失函数
> 神经网络以某个指标为线索寻找最优权重参数。神经网络的学习中所用的指标称为损失函数（loss function）。这个损失函数可以使用任意函数，但一般用均方误差和交叉熵误差等
* 损失函数是表示神经网络性能的“恶劣程度”的指标，即当前的神经网络对监督数据在多大程度上不拟合，在多大程度上不一致

#### one-hot表示
> 将正确解标签表示为1，其他标签表示为0的表示方法称为one-hot表示

#### 均方误差
![image](https://user-images.githubusercontent.com/13389058/157396403-158612f2-13f8-4551-a068-093dc06b86d7.png)


#### 交叉熵误差
![image](https://user-images.githubusercontent.com/13389058/157397973-fff18dcb-7dca-40bb-b625-0bb57675967a.png)
* 交叉熵误差的值是由正确解标签所对应的输出结果决定的

#### mini-batch学习
> 
