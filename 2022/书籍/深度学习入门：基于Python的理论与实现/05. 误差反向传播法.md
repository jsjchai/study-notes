## 误差反向传播法
### 正向传播
> 正向传播是从计算图出发点到结束点的传播
### 反向传播
> 反向传播是从计算图结束点到出发点的传播
### 计算图有什么优点
1. 无论全局是多么复杂的计算，都可以通过局部计算使各个节点致力于简单的计算;
2. 利用计算图可以将中间的计算结果全部保存起来;
3. 可以通过反向传播高效计算导数;
4. 可以通过正向传播和反向传播高效地计算各个变量的导数值;
### 链式法则
> 如果某个函数由复合函数表示，则该复合函数的导数可以用构成复合函数的各个函数的导数的乘积表示
### Affine层
> 神经网络的正向传播中进行的矩阵的乘积运算在几何学领域被称为“仿射变换”A。因此，这里将进行仿射变换的处理实现为“Affine层”。
### Softmax层
> Softmax层将输入值正规化（将输出值的和调整为1）之后再输出
* 神经网络中进行的处理有推理（inference）和学习两个阶段。
* 神经网络的推理通常不使用 Softmax层
* 神经网络的学习阶段则需要 Softmax层
### 神经网络的学习
> 神经网络中有合适的权重和偏置，调整权重和偏置以便拟合训练数据的过程称为学习
1. 从训练数据中随机选择一部分数据;
2. 计算损失函数关于各个权重参数的梯度;
3. 将权重参数沿梯度方向进行微小的更新;
4. 重复步骤1、步骤2、步骤3;

### 求梯度的方法
1. 基于数值微分的方法;
    * 数值微分的优点是实现简单，因此，一般情况下不太容易出错
2. 解析性地求解数学式的方法;
    * 通过使用误差反向传播法，即使存在大量的参数，也可以高效地计算梯度
    * 误差反向传播法的实现很复杂，容易出错
### 梯度确认
> 确认数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（严格地讲，是非常相近）的操作称为梯度确认（gradient check）。
