## Gated RNN

### RNN的问题
* 梯度在中途变弱(甚至没有包含任何信息),则权重参数将不会被更新
* RNN层无法学习长期的依赖关系
* 梯度消失(避免梯度变小)
* 梯度爆炸(避免梯度变大
* RNN层的激活函数一般使用tanh函数,如果改为ReLU函数,则有希望抑制梯度消失

#### 矩阵的奇异值
> 表示数据的离散程度 
