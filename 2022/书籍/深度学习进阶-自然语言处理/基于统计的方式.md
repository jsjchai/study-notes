
## 文本相似度
* 基于统计的方式
* 基于推理的方式
### 基于统计的方式(基于计数的方式)
> 基于计数方式的目标就是从语料库中自动高效地提取本质
* 基于计数的方法根据一个单词周围的单词出现的频率来表示该单词
* 先生成所有单词的共现矩阵,再对这个矩阵进行SVD,以获得密集向量(单词的分布式表示)
* 缺点
  * 对于一个n*n的矩阵,SVD的复杂度是O(n<sup>3</sup>) .计算成本过高
#### 单词的分布式表示
> 构建一个密集向量（Dense Vector）来表征一个词汇,密集向量指向量的各个元素（大多数）是由非0实数表示的
#### 分布式假设
> 某个单词的含义由它周围的单词形成。单词本身没有含义，单词的含义由它所在的上下文（语境）形成
#### 共现矩阵
* you say goodbye and I say hello.

| | you  |say  |goodbye|and|I|hello|.|
|  :----:  | :----:  | :----:  | :----:  | :----:  | :----:  | :----:  | :----:  |
| you|0| 1|0|0|0|0|0|
| say| 1| 0|1|0|1|1|0|
|goodbye|0|1|0|1|0|0|0|
|and|0|0|1|0|1|0|0|
|I |0|1|0|1|0|0|0|
|hello |0|1|0|0|0|0|1|
|. |0|0|0|0|0|1|0|

#### 向量间的相似度
* 余弦相似度 
> 在信息检索中，每个词项被赋予不同的维度，而一个文档由一个向量表示，其各个维度上的值对应于该词项在文档中出现的频率。余弦相似度因此可以给出两篇文档在其主题方面的相似度
![image](https://user-images.githubusercontent.com/13389058/155826597-bde412bf-41b2-402b-b980-5fc7fe9eadfe.png)


#### 点互信息PMI
![image](https://user-images.githubusercontent.com/13389058/155826614-e02cb53a-5d2c-46ba-b78f-6098311611e8.png)
* 当两个单词的共现次数为0时,log<sub>2</sub>0=-∞,实际当中会使用正的点互信息PPMI
#### 正的点互信息PPMI
* PPMI(x,y)=max(0,PMI(x,y))


#### 降维
> 减少向量的维度(尽量保留“重要信息”)的基础上减少
* 向量容易受到噪声影响,稳健性差,常见方法是向量降维
* 常见的降维方法
  * 奇异值分解SVD 

