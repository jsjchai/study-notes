# 自然语言和单词的分布式表示
## 什么是自然语言处理
> 自然语言处理（英语：Natural Language Processing，缩写作 NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言处理包括多方面和步骤，基本有认知、理解、生成等部分。
自然语言认知和理解是让电脑把输入的语言变成有意思的符号和关系，然后根据目的再处理。自然语言生成系统则是把计算机数据转化为自然语言
## 应用场景
* 机器翻译
* 搜索引擎
* 语音助手
## 自然语言处理技术与方法
### 语法技术
* 解析                
* 分词
  我/要/去/北京
* 断句
* 形态分割
* 词干
### 语义技术
* 词义消歧
* 命名实体识别
* 自然语言生成
## 单词含义表示的方法
> 我们的语言是由文字构成的，而语言的含义是由单词构成的。换句话说，单词是含义的最小单位。因此，为了让计算机理解自然语言，让它理解单词含义可以说是最重要的事情了
### 基于同义词词典的方法
> 要表示单词含义，首先可以考虑通过人工方式来定义单词含义。一种方法是像《新华字典》那样，一个词一个词地说明单词含义。比如，当你用字典查“汽车”这个单词时，就会看到“装有车轮并依靠它们前行的交通工具或运输工具……”这样的说明。通过像这样定义单词，计算机或许也能够理解单词含义
像这样，通过对所有单词创建近义词集合，并用图表示各个单词的关系，可以定义单词之间的联系。利用这个“单词网络”，可以教会计算机单词之间的相关性
#### WordNet
在自然语言处理领域，最著名的同义词词典是WordNet.  使用WordNet，可以获得单词的近义词，或者利用单词网络。使用单词网络，可以计算单词之间的相似度
#### 同义词词典的问题
* 语言的含义也会随着时间的推移而变化
* 词义需要标注,人力成本高
* 无法表示单词的微妙差异
### 基于计数的方法
#### 语料库
> 语料库就是大量的文本数据。不过，语料库并不是胡乱收集数据，一般收集的都是用于自然语言处理研究和应用的文本数据。比如:  中文人名语料库
语料库中包含了大量的关于自然语言的实践知识，即文章的写作方法、单词的选择方法和单词含义等。基于计数的方法的目标就是从这些富有实践知识的语料库中，自动且高效地提取本质
#### 单词的分布式表示
> 考虑如何基于分布式假设使用向量表示单词，最直截了当的实现方法是对周围单词的数量进行计数。具体来说，在关注某个单词的情况下，对它的周围出现了多少次什么单词进行计数，然后再汇总。这里，我们将这种做法称为“基于计数的方法”，或者称为“基于统计的方法”
构建一个密集向量（Dense Vector）来表征一个词汇,密集向量指向量的各个元素（大多数）是由非0实数表示的 例如: you say goodbye and I say hello.

* 可以用0100000表示you
#### 向量间的相似度
##### 余弦相似度
```python
import spacy

nlp = spacy.load("zh_core_web_lg")
doc1 = nlp("最近有什么新的电影吗？")
doc2 = nlp("最近新上映什么电影")
doc3 = nlp("我去看电影了")

print(doc1.similarity(doc2))
print(doc1.similarity(doc3))
print(doc2.similarity(doc3))
```

### 基于推理的方法

**you  ?  goodbye and I say hello**

> 当给出周围的单词（上下文）时，预测“?”处会出现什么单词，这就是推理.基于推理的方法引入了某种模型，我们将神经网络用于此模型。这个模型接收上下文信息作为输入，并输出（可能出现的）各个单词的出现概率。在这样的框架中，使用语料库来学习模型，使之能做出正确的预测
### 代码示例
```python
## 分词
from spacy.lang.zh import Chinese

# pip install https://github.com/lancopku/pkuseg-python/archive/master.zip

# Load pkuseg model in spaCy Chinese tokenizer
cfg = {"segmenter": "pkuseg"}
nlp = Chinese.from_config({"nlp": {"tokenizer": cfg}})
nlp.tokenizer.initialize(pkuseg_model="mixed")

# seg = pkuseg.pkuseg()
# text = seg.cut('我爱北京天安门')
# print(text)

doc = nlp("兵乓球拍卖完了")
for token in doc:
    print(token)
```   
```python
## 词性
import spacy

nlp = spacy.load("zh_core_web_lg")
doc = nlp("我要去北京")

for token in doc:
    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,
          token.shape_, token.is_alpha, token.is_stop)
```
```python
## 分句
import spacy

nlp = spacy.load("zh_core_web_lg")
doc = nlp("生命，也许是宇宙之间唯一就应受到崇拜的因素。生命的孕育、诞生和显示本质是一种无比激动人心的过程。生命像音乐和画面一样暗自挟带着一种命定的声调或血色，当它遇到大潮的袭卷，当它听到号角的催促时，它会顿时抖擞，露出本质的绚烂和激昂。当然，这本质更可能是卑污、懦弱、乏味的；它的主人并无选取的可能。")
assert doc.has_annotation("SENT_START")
for sent in doc.sents:
    print(sent.text)
```
```python
## 词向量
import spacy

nlp = spacy.load("zh_core_web_lg")
tokens = nlp("我要去北京")

for token in tokens:
    print(token.text, token.has_vector, token.vector_norm, token.is_oov)
```
```python
## 短语提取
import spacy

nlp = spacy.load("en_core_web_sm")
doc = nlp("Autonomous cars shift insurance liability toward manufacturers")
for chunk in doc.noun_chunks:
    print(chunk.text, chunk.root.text, chunk.root.dep_,chunk.root.head.text)
```
```python
## 命名实体识别
import spacy

nlp = spacy.load("zh_core_web_lg")
doc = nlp("2022年我要去北京")

for ent in doc.ents:
    print(ent.text, ent.start_char, ent.end_char, ent.label_)
```

