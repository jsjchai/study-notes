## 定义
### 大模型
> 指具有大量参数和复杂结构的机器学习模型，能够处理海量数据、完成各种复杂的任务，如自然语言处理、计算机视觉、语音识别等。
### 超大模型
> 超大模型是大模型的一个子集，它们的参数量远超过大模型
### 大语言模型(Large Language Model)
> 通常是具有大规模参数和计算能力的自然语言处理模型，例如 OpenAl 的 GPT-3 模型。这些模型可以通过大量的数据和参数进行训练，以生成人类类似的文本或回答自然语言的问题。大型语言模型在自然语言处理、文本生成和智能对话等领域有广泛应用
### GPT (Generative Pretrained Transformer)
> GPT 和ChatGPT都是基于FTransformer架构的语言模型，但它们在设计和应用上存在区别:GPT模型旨在生成自然语言文本并处理各种自然语言处理任务，如文本生成、翻译、摘要等。它通常在单向生成的情况下使用，即根据给定的文本生成连贯的输出
### ChatGPT
> ChatGPT则专注于对话和交互式对话。它经过特定的训练，以更好地处理多轮对话和上下文理解。ChatGPT设计用于提供流畅、连贯和有趣的对话体验，以响应用户的输入并生成合适的回复。
## 大模型发展历程
* 萌芽期 (1950-2005) 以CNN为代表的传统神经网络模型阶段
* 探索沉淀期 (2006-2019) 以Transformer为代表的全新神经网络模型阶段
* 迅猛发展期 (2020-至今) 以GPT为代表的预训练大模型阶段
##  大模型的分类
### 按照输入数据类型
#### 语言大模型(NLP)
> 指在自然语言处理(NaturalLanguage Processing，NLP)领域中的一类大模型，通常用于处理文本数据和理解自然语言。这类大模型的主要特点是它们在大规模语料库上进行了训练，以学习自然语言的各种语法、语义和语境规则。例如:GPT系列 (OpenAl) 、Bard (Google) 、文心一言 (百度)
