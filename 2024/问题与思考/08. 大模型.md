## 定义
### 大模型
> 指具有大量参数和复杂结构的机器学习模型，能够处理海量数据、完成各种复杂的任务，如自然语言处理、计算机视觉、语音识别等。
### 超大模型
> 超大模型是大模型的一个子集，它们的参数量远超过大模型
### 大语言模型(Large Language Model)
> 通常是具有大规模参数和计算能力的自然语言处理模型，例如 OpenAl 的 GPT-3 模型。这些模型可以通过大量的数据和参数进行训练，以生成人类类似的文本或回答自然语言的问题。大型语言模型在自然语言处理、文本生成和智能对话等领域有广泛应用
### GPT (Generative Pretrained Transformer)
> GPT 和ChatGPT都是基于FTransformer架构的语言模型，但它们在设计和应用上存在区别:GPT模型旨在生成自然语言文本并处理各种自然语言处理任务，如文本生成、翻译、摘要等。它通常在单向生成的情况下使用，即根据给定的文本生成连贯的输出
### ChatGPT
> ChatGPT则专注于对话和交互式对话。它经过特定的训练，以更好地处理多轮对话和上下文理解。ChatGPT设计用于提供流畅、连贯和有趣的对话体验，以响应用户的输入并生成合适的回复。
## 大模型发展历程
* 萌芽期 (1950-2005) 以CNN为代表的传统神经网络模型阶段
* 探索沉淀期 (2006-2019) 以Transformer为代表的全新神经网络模型阶段
* 迅猛发展期 (2020-至今) 以GPT为代表的预训练大模型阶段
##  大模型的分类
### 按照输入数据类型
#### 语言大模型(NLP)
> 指在自然语言处理(NaturalLanguage Processing，NLP)领域中的一类大模型，通常用于处理文本数据和理解自然语言。这类大模型的主要特点是它们在大规模语料库上进行了训练，以学习自然语言的各种语法、语义和语境规则。例如:GPT系列 (OpenAl) 、Bard (Google) 、文心一言 (百度)
#### 视觉大模型(CV)
> 指在计算机视觉(Computer Vision，CV)领中使用的大模型，通常用于图像外理和分析。这类模型通过在大规模图像数据上进行训练，可以实现各种视觉任务，如图像分类、目标检测、图像分割、姿态估计、人脸识别等。例如: VIT系列(Google) 、文心UFO、华为盘古CV、INTERN (商汤)
#### 多模态大模型
> 指能够处理多种不同类型数据的大模型，例如文本、图像、音频等多模态数据。这类模型结合了NLP和CV的能力，以实现对多模态信息的综合理解和分析，从而能够更全面地理解和处理复杂的数据。例如: DingoDB多模向量数据库(九章云极DataCanvas)、DALL-E(OpenAl)、悟空画画(华为) 、midjourney。
### 按照应用领域
#### 通用大模型L0
> 指可以在多个领域和任务上通用的大模型。它们利用大算力、使用海量的开放数据与具有巨量参数的深度学习算法在大规模无标注数据上进行训练，以寻找特征并发现规律，进而形成可“举一反三"的强大泛化能力，可在不进行微调或少量微调的情况下完成多场景任务，相当于AI完成了“通识教育”
#### 行业大模型L1
> 指那些针对特定行业或领域的大模型。它们通常使用行业相关的数据进行预训练或微调，以提高在该领域的性能和准确度，相当于AI成为“行业专家”
#### 垂直大模型L2
> 指那些针对特定任务或场景的大模型。它们通常使用任务相关的数据进行预训练或微调，以提高在该任务上的性能和效果
## 模型的泛化与微调
### 模型的泛化能力
> 指一个模型在面对新的、未见过的数据时，能够正确理解和预测这些数据的能力。在机器学习和人工智能领域，模型的泛化能力是评估模型性能的重要指标之一
### 模型的微调
> 给定预训练模型(Pre-trained model)，基于模型进行微调(Fine Tune) 。相对于从头开始训练(Training a modelfrom scatch)，微调可以省去大量计算资源和计算时间，提高计算效率，甚至提高准确率。
* 模型微调的基本思想是使用少量带标签的数据对预训练模型进行再次训练，以适应特定任务。在这个过程中，模型的参数会根据新的数据分布进行调整。这种方法的好外在于，它利用了预训练模型的强大能力，同时还能够适应新的数据分。因此，模型微调能够提高模型的泛化能力，减少过拟合现象。
#### 模型微调方法
*  Fine-tuning  通过在预训练模型的最后一层添加一个新的分类层，然后根据新的数据集进行微调。
*  Feature augmentation 通过向数据中添加一些人工特征来增强模型的性能。这些特征可以是手工设计的，也可以是通过自动特征生成技术生成的。
*  Transfer leamning 使用在一个任务上训练过的模型作为新任务的起点，然后对模型的参数进行微调，以适应新的任务
## 大模型人类偏好对齐
### 主要任务
> 大模型在预训练阶段的主要任务是将世界知识融入模型中,是**模型学习知识的过程**。对齐大模型与人类偏好的目标是激发模型理解、适应人类意愿和解决问题的能力,强调的是使模型能够有效地应用预训练阶段获取的知识,从而使其具有多样化的能力,能够解决各种问题
### 偏见和歧视性信息
> 大模型在训练阶段可能会学习到数据中的偏见和歧视性信息,导致模型的行为表现出预期外的特征。为了纠正模型的表现,使模型反映出人类的价值观,避免出现不可预测的输出,需要实现大模型与人类偏好的对齐。目前主要通过两种方法实现:
* 有监督微调
* 人类反馈的强化学习算法 (ReinforcementLearningfromHumanFeedback,RLHF)
<img width="546" alt="image" src="https://github.com/jsjchai/study-notes/assets/13389058/8b389ea8-e6f9-4695-a8ec-3676e25cc0a6">

## 参考文档
* [大模型关键技术与未来发展方向](https://www.nsfc.gov.cn/csc/20345/20348/pdf/2023/202305-758-766.pdf)
* [什么是大模型](https://xie.infoq.cn/article/c73d7cd6c89fa88279e6e0afe)



