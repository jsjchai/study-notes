## 底座
> 通常指的是大型语言模型（Large Language Model，LLM）的基础版本，它们是构建特定领域模型（如医疗大模型）的起点。
### 不同的底座模型差别
1. 参数量：不同底座模型的参数数量可能不同，如上文提到的2.7B和7B，这代表了模型的规模和复杂度。
2. 架构设计：底座模型可能采用不同的神经网络架构，如Transformer、BERT、GPT等，这些架构决定了模型处理数据的方式。
3. 预训练数据：底座模型在预训练阶段使用的数据集可能不同，这影响了模型学习到的知识和能力。
4. 微调方法：即使是相同规模的底座模型，采用的微调方法（如指令微调、持续预训练等）也可能导致性能和应用场景的差异。
5. 领域适应性：底座模型在经过特定领域的微调后，其对特定领域数据的理解和生成能力会有显著差异。
6. 性能：不同底座模型在特定任务上的表现可能不同，这取决于它们的设计、训练过程和微调策略。
7. 资源需求：不同规模和复杂度的底座模型对计算资源的需求也不同，大规模模型通常需要更多的计算能力和存储空间。
8. 开源与闭源：一些底座模型可能是开源的，允许研究者和开发者自由使用和修改；而另一些可能是闭源的，使用受限或需要特定的许可。
9. 社区支持和生态：不同底座模型背后的社区支持和生态系统的完善程度也会影响开发者的选择和模型的应用。
## 数据集
> 训练大型语言模型（LLMs）需要多种类型的数据集，这些数据集支撑模型学习语言的各个方面以及特定领域的知识。
### 关键数据集类型
* 通用语料库：这些是大规模的文本集合，包含了各种主题和风格的文本。它们用于训练模型的通用语言理解能力。例如，维基百科、书籍、新闻文章和其他公开的文本资源。
* 特定领域的文本：对于特定领域的应用（如医疗、法律、科学等），需要该领域大量的专业文献、学术论文、技术手册、案例研究等。
* 问答对：包含问题和答案的数据集，用于训练模型理解问题并生成恰当回答的能力。在医疗领域，这可能包括病人和医生之间的对话记录。
* 对话语料：多轮对话的数据集，可以帮助模型学习如何在对话中保持上下文连贯性。
* 标注数据：带有词性标注、句法树、实体识别等信息的文本数据，用于训练模型的理解和生成结构化信息的能力。
* 多模态数据：结合文本、图像、声音等多种类型的数据，用于训练模型处理和理解跨模态信息。
* 指令数据：包含指令和完成指令所需步骤的数据，有助于训练模型遵循指令完成任务。
* 评估集：用于测试模型性能的数据集，通常不用于训练，而是用来评估模型在特定任务上的表现。
* 微调样本：在通用模型基础上，使用特定领域的数据进行微调，以提高模型在该领域的性能。
* 知识库：如医疗知识库、法律数据库等，包含结构化的知识信息，可用于增强模型在特定领域的知识储备。
* 模拟数据：在一些领域，可能需要使用模拟生成的数据来增强模型的泛化能力。
* 用户生成内容：如社交媒体帖子、论坛讨论等，这些数据反映了真实世界中的语言使用情况。

